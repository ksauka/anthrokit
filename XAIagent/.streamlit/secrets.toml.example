# ============================================================================
# AnthroKit Streamlit Secrets Configuration Template
# ============================================================================
# 
# USAGE:
#   1. Copy this file to: .streamlit/secrets.toml (DO NOT commit secrets.toml!)
#   2. Fill in your actual values
#   3. For Streamlit Cloud: Copy contents to App Settings → Secrets
#
# IMPORTANT: Never commit actual secrets to Git!
# ============================================================================

# ----------------------------------------------------------------------------
# GitHub Logging (REQUIRED for data collection)
# ----------------------------------------------------------------------------
# Session logs are saved to private GitHub repo instead of local files
# This works on Streamlit Cloud (no persistent filesystem)
#
# Setup:
#   1. Create private GitHub repo (e.g., "hicxai-data-private")
#   2. Generate personal access token with 'repo' scope:
#      GitHub → Settings → Developer settings → Personal access tokens
#   3. Fill in values below:

GITHUB_TOKEN = "YOUR_GITHUB_TOKEN_HERE"
GITHUB_REPO = "https://github.com/YOUR_USERNAME/YOUR_PRIVATE_REPO.git"

# ----------------------------------------------------------------------------
# Qualtrics Integration (REQUIRED for study flow)
# ----------------------------------------------------------------------------
# NOT USED: Participants come from Qualtrics with 'return' parameter
# No standalone Qualtrics redirect needed
# App returns to Qualtrics using the 'return' URL from query params

# If you need a fallback Qualtrics URL (optional):
# QUALTRICS_URL = "https://yoursurvey.qualtrics.com/jfe/form/SV_xxxxxxxxxxxxx"

# ----------------------------------------------------------------------------
# Experimental Condition Configuration (REQUIRED - Different per app)
# ----------------------------------------------------------------------------
# Deploy 6 separate apps with different values:
#
# App 1 (NoA_Fixed):       app_nonanthro.py
#   PERSONALITY_ADAPTATION = "disabled"
#   ANTHROPOMORPHISM = "none"
#
# App 2 (NoA_Adapted):     app_nonanthro_personalize.py
#   PERSONALITY_ADAPTATION = "enabled"
#   ANTHROPOMORPHISM = "none"
#
# App 3 (LowA_Fixed):      app_condition_5.py
#   PERSONALITY_ADAPTATION = "disabled"
#   ANTHROPOMORPHISM = "low"
#
# App 4 (LowA_Adapted):    app_condition_5_personality.py
#   PERSONALITY_ADAPTATION = "enabled"
#   ANTHROPOMORPHISM = "low"
#
# App 5 (HighA_Fixed):     app_v1.py
#   PERSONALITY_ADAPTATION = "disabled"
#   ANTHROPOMORPHISM = "high"
#
# App 6 (HighA_Adapted):   app_v1_personality.py
#   PERSONALITY_ADAPTATION = "enabled"
#   ANTHROPOMORPHISM = "high"

PERSONALITY_ADAPTATION = "disabled"  # "enabled" or "disabled"
ANTHROPOMORPHISM = "none"            # "none", "low", or "high"

# ----------------------------------------------------------------------------
# LLM Backend Configuration (REQUIRED)
# ----------------------------------------------------------------------------
# Choose ONE backend: OpenAI or Ollama

# Option 1: OpenAI (Recommended for production)
OPENAI_API_KEY = "YOUR_OPENAI_API_KEY_HERE"

# Optional OpenAI settings:
# OPENAI_MODEL = "gpt-4o-mini"  # Default model
# OPENAI_BASE_URL = ""          # Custom endpoint (leave blank for default)

# Option 2: Ollama (For local development)
# OLLAMA_BASE_URL = "http://localhost:11434"
# OLLAMA_MODEL = "llama3.1:8b"

# ----------------------------------------------------------------------------
# Debug Mode (Optional)
# ----------------------------------------------------------------------------
# Enable verbose logging for troubleshooting
# Set to "true" only during testing

DEBUG_MODE = "false"

